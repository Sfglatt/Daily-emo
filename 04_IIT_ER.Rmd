---
title: "04_IIT_ER"
author: "Sglatt"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Packages}
options(repos = c(CRAN = "https://cloud.r-project.org"))

if (!require("apaTables")) {install.packages("apaTables"); require("apaTables")} 
if (!require("car")) {install.packages("car"); require("car")} 
if (!require("descr")) {install.packages("descr"); require("descr")}
if (!require("CCA")) {install.packages("CCA"); require("CCA")}
if (!require("CCP")) {install.packages("CCP"); require("CCP")}
if (!require("devtools")) {install.packages("devtools"); require("devtools")} 
# devtools::install_github("DoctorBJones/datadictionary"); require ("datadictionary")
if (!require("dplyr")) {install.packages("dplyr"); require("dplyr")}
if (!require("GGally")) {install.packages("GGally"); require("GGally")}
if (!require("gridExtra")) {install.packages("gridExtra"); require("gridExtra")}
if (!require("readxl")) {install.packages("readxl"); require("readxl")}
if (!require("stringr")) {install.packages("stringr"); require("stringr")}
if (!require("summarytools")) {install.packages("summarytools"); require("summarytools")} 
if (!require("tidyverse")) {install.packages("tidyverse"); require("tidyverse")}
if (!require("writexl")) {install.packages("writexl"); require("writexl")}
```

```{r Data}
EMA_df <- readxl::read_xlsx("Data/EMA_cleaned_8.22.24.xlsx")
colnames(EMA_df) <- gsub(" ", "_", colnames(EMA_df)) 
# glimpse(EMA_df)
```

```{r IIT affect indices}
EMA_df <- EMA_df %>%
  mutate(
    
    ### "How positive do you feel (on a sliding scale from 0 to 100)?" [_pos_1]
    
    # Average for the negative scenarios (N1_pos_1, N2_pos_1, etc.)
    N_pos_avg = rowMeans(select(., starts_with("N")) %>% select(ends_with("_pos_1")), na.rm = TRUE),
    
    # Average for the positive scenarios (P1_pos_1, P2_pos_1, etc.)
    P_pos_avg = rowMeans(select(., starts_with("P")) %>% select(ends_with("_pos_1")), na.rm = TRUE),
    
    # Average for both the positive and negative scenarios 
    NP_pos_avg = rowMeans(select(., matches("^[NP]\\d+_pos_1$")), na.rm = TRUE),
    
    
    ### "How negative do you feel (on a sliding scale from 0 to 100)?" [_neg_1]
    
    # Average for the negative scenarios (N1_neg_1, N2_neg_1, etc.)
    N_neg_avg = rowMeans(select(., starts_with("N")) %>% select(ends_with("_neg_1")), na.rm = TRUE),
    
    # Average for the positive scenarios (P1_neg_1, P2_neg_1, etc.)
    P_neg_avg = rowMeans(select(., starts_with("P")) %>% select(ends_with("_neg_1")), na.rm = TRUE),
    
    # Average for the positive and negative scenarios 
    NP_neg_avg = rowMeans(select(., matches("^[NP]\\d+_neg_1$")), na.rm = TRUE),
    
    
    ### "After having these thoughts, how positive do you feel now (on a sliding scale from 0 to 100)?" [_ERpos_1]
    
    # Average for the negative scenarios (N1_ERpos_1, N2_ERpos_1, etc.)
    N_ERpos_avg = rowMeans(select(., starts_with("N")) %>% select(ends_with("_ERpos_1")), na.rm = TRUE),
    
    # Average for the positive scenarios (P1_ERpos_1, P2_ERpos_1, etc.)
    P_ERpos_avg = rowMeans(select(., starts_with("P")) %>% select(ends_with("_ERpos_1")), na.rm = TRUE),
    
    # Average for both the positive and negative scenarios 
    NP_ERpos_avg = rowMeans(select(., matches("^[NP]\\d+_ERpos_1$")), na.rm = TRUE),
    
    
    ### "After having these thoughts, how negative do you feel now (on a sliding scale from 0 to 100)?" [_ERneg_1]
    
    # Average for the negative scenarios (N1_ERneg_1, N2_ERneg_1, etc.)
    N_ERneg_avg = rowMeans(select(., starts_with("N")) %>% select(ends_with("_ERneg_1")), na.rm = TRUE),
    
    # Average for the positive scenarios (P1_ERneg_1, P2_ERneg_1, etc.)
    P_ERneg_avg = rowMeans(select(., starts_with("P")) %>% select(ends_with("_ERneg_1")), na.rm = TRUE),
    
    # Average for both the negative and negative scenarios 
    NP_ERneg_avg = rowMeans(select(., matches("^[NP]\\d+_ERneg_1$")), na.rm = TRUE),
    
    
    ### change score from pre [_pos_1 / _neg_1] and post [_ERpos_1 / _ERneg_1] IIT *averages*
    
    N_pos_change = N_ERpos_avg - N_pos_avg,
    N_neg_change = N_ERneg_avg - N_neg_avg,
    
    P_pos_change = P_ERpos_avg - P_pos_avg,
    P_neg_change = P_ERneg_avg - P_neg_avg,
    
    NP_pos_change = NP_ERpos_avg - NP_pos_avg,
    NP_neg_change = NP_ERneg_avg - NP_neg_avg,
    
    # Average of all ER items (*not averages*) in negative scenarios (N1_ER_1 through N12_ER_7)
    N_ER_avg_1 = rowMeans(select(., matches("^N\\d+_ER_\\d+$")), na.rm = TRUE),
    
    # Average of all ER items (*not averages*) in positive scenarios (P1_ER_1 through P12_ER_7)
    P_ER_avg_1 = rowMeans(select(., matches("^P\\d+_ER_\\d+$")), na.rm = TRUE),
    
    # Average of all ER items (*not averages) across negative and positive scenarios (N1_ER_1-N12_ER_7 and P1_ER_1-P12_ER_7)
    NP_ER_avg_1 = rowMeans(select(., matches("^[NP]\\d+_ER_\\d+$")), na.rm = TRUE)
  )
# Verify that the above called the right averages (and not something that was created)
grep("^P\\d+_ER_\\d+$", colnames(EMA_df), value = TRUE)
grep("^N\\d+_ER_\\d+$", colnames(EMA_df), value = TRUE)

grep("^[NP]\\d+_pos_1$", colnames(EMA_df), value = TRUE)
grep("^[NP]\\d+_neg_1$", colnames(EMA_df), value = TRUE)

grep("^[NP]\\d+_ER_\\d+$", colnames(EMA_df), value = TRUE)

grep("^[NP]\\d+_ERpos_1$", colnames(EMA_df), value = TRUE)
grep("^[NP]\\d+_ERneg_1$", colnames(EMA_df), value = TRUE)

EMA_df %>%  select(starts_with("N") & ends_with("_pos_1"))
EMA_df %>%  select(starts_with("P") & ends_with("_pos_1"))

EMA_df %>%  select(starts_with("N") & ends_with("_neg_1"))
EMA_df %>%  select(starts_with("P") & ends_with("_neg_1"))

EMA_df %>%  select(starts_with("N") & ends_with("ERpos_1"))
EMA_df %>%  select(starts_with("P") & ends_with("ERpos_1"))

EMA_df %>%  select(starts_with("N") & ends_with("ERneg_1"))
EMA_df %>%  select(starts_with("P") & ends_with("ERneg_1"))

EMA_df <- EMA_df %>%
  mutate(
    ### Seven ER questions after each scenario
    # ER_1 "I’m savoring this moment and feeling up for anything"
    # ER_2 "Whatever positive feelings I have right now will end soon. I have to accept that this has happened"
    # ER_3 "I dwell upon the feelings this situation has evoked in me"
    # ER_4 "I think about how I can best cope with the situation"
    # ER_5 "I change the way I was thinking in order to feel less negative emotion or more positive emotion"
    # ER_6 "think this hasn’t been too bad compared to other things"
    # ER_7 "I try to do other things to take my mind off it." 
    
    # Averages for each ER set (above) in negative scenarios
    N1_ER_avg = rowMeans(select(., starts_with("N1_ER_")), na.rm = TRUE), 
    N2_ER_avg = rowMeans(select(., starts_with("N2_ER_")), na.rm = TRUE),
    N3_ER_avg = rowMeans(select(., starts_with("N3_ER_")), na.rm = TRUE),
    N4_ER_avg = rowMeans(select(., starts_with("N4_ER_")), na.rm = TRUE),
    N5_ER_avg = rowMeans(select(., starts_with("N5_ER_")), na.rm = TRUE),
    N6_ER_avg = rowMeans(select(., starts_with("N6_ER_")), na.rm = TRUE),
    N7_ER_avg = rowMeans(select(., starts_with("N7_ER_")), na.rm = TRUE),
    N8_ER_avg = rowMeans(select(., starts_with("N8_ER_")), na.rm = TRUE),
    N9_ER_avg = rowMeans(select(., starts_with("N9_ER_")), na.rm = TRUE),
    N10_ER_avg = rowMeans(select(., starts_with("N10_ER_")), na.rm = TRUE),
    N11_ER_avg = rowMeans(select(., starts_with("N11_ER_")), na.rm = TRUE),
    N12_ER_avg = rowMeans(select(., starts_with("N12_ER_")), na.rm = TRUE),
    
    # Averages for each ER set in positive scenarios
    P1_ER_avg = rowMeans(select(., starts_with("P1_ER_")), na.rm = TRUE),
    P2_ER_avg = rowMeans(select(., starts_with("P2_ER_")), na.rm = TRUE),
    P3_ER_avg = rowMeans(select(., starts_with("P3_ER_")), na.rm = TRUE),
    P4_ER_avg = rowMeans(select(., starts_with("P4_ER_")), na.rm = TRUE),
    P5_ER_avg = rowMeans(select(., starts_with("P5_ER_")), na.rm = TRUE),
    P6_ER_avg = rowMeans(select(., starts_with("P6_ER_")), na.rm = TRUE),
    P7_ER_avg = rowMeans(select(., starts_with("P7_ER_")), na.rm = TRUE),
    P8_ER_avg = rowMeans(select(., starts_with("P8_ER_")), na.rm = TRUE),
    P9_ER_avg = rowMeans(select(., starts_with("P9_ER_")), na.rm = TRUE),
    P10_ER_avg = rowMeans(select(., starts_with("P10_ER_")), na.rm = TRUE),
    P11_ER_avg = rowMeans(select(., starts_with("P11_ER_")), na.rm = TRUE),
    P12_ER_avg = rowMeans(select(., starts_with("P12_ER_")), na.rm = TRUE),
    
    # Average of all ER averages in negative scenarios (N1_ER_1:N1_ER_7, N2_ER_1:N2_ER_7, etc.)
    N_ER_avg_2 = rowMeans(select(., starts_with("N") & ends_with("_ER_avg")), na.rm = TRUE),
    
    # Average of all ER averages in positive scenarios (P1_ER_1:P1_ER_7, P2_ER_1:P2_ER_7, etc.)
    P_ER_avg_2 = rowMeans(select(., starts_with("P") & ends_with("_ER_avg")), na.rm = TRUE),
    
    # Average of all ER averages across positive and negative scenarios 
    NP_ER_avg_2 = rowMeans(select(., ends_with("_ER_avg")), na.rm = TRUE),
    
    ## _avg_2 are checks! I think they should be the same as avg_1 if done correctly
  )

# Verify that these called the right averages (and not something else that was created above) 
EMA_df %>%  select(starts_with("N") & ends_with("_ER_avg"))
EMA_df %>%  select(starts_with("P") & ends_with("_ER_avg"))
EMA_df %>%  select(ends_with("_ER_avg"))

# 9/13 meeting update; average of each strategy use across scenarios
EMA_df <- EMA_df %>%
  mutate(
    # Average of emotion strategies in negative scenarios
    N_ER_avg_1 = rowMeans(select(., matches("^N\\d+_ER_1$")), na.rm = TRUE),
    N_ER_avg_2 = rowMeans(select(., matches("^N\\d+_ER_2$")), na.rm = TRUE),
    N_ER_avg_3 = rowMeans(select(., matches("^N\\d+_ER_3$")), na.rm = TRUE),
    N_ER_avg_4 = rowMeans(select(., matches("^N\\d+_ER_4$")), na.rm = TRUE),
    N_ER_avg_5 = rowMeans(select(., matches("^N\\d+_ER_5$")), na.rm = TRUE),
    N_ER_avg_6 = rowMeans(select(., matches("^N\\d+_ER_6$")), na.rm = TRUE),
    N_ER_avg_7 = rowMeans(select(., matches("^N\\d+_ER_7$")), na.rm = TRUE),
    
    # Average of emotion strategies in positive scenarios
    P_ER_avg_1 = rowMeans(select(., matches("^P\\d+_ER_1$")), na.rm = TRUE),
    P_ER_avg_2 = rowMeans(select(., matches("^P\\d+_ER_2$")), na.rm = TRUE),
    P_ER_avg_3 = rowMeans(select(., matches("^P\\d+_ER_3$")), na.rm = TRUE),
    P_ER_avg_4 = rowMeans(select(., matches("^P\\d+_ER_4$")), na.rm = TRUE),
    P_ER_avg_5 = rowMeans(select(., matches("^P\\d+_ER_5$")), na.rm = TRUE),
    P_ER_avg_6 = rowMeans(select(., matches("^P\\d+_ER_6$")), na.rm = TRUE),
    P_ER_avg_7 = rowMeans(select(., matches("^P\\d+_ER_7$")), na.rm = TRUE),
    
    # Average of emotion strategies across positive/negative scenarios
    NP_ER_avg_1 = rowMeans(select(., matches("^[NP]\\d+_ER_1$")), na.rm = TRUE),
    NP_ER_avg_2 = rowMeans(select(., matches("^[NP]\\d+_ER_2$")), na.rm = TRUE),
    NP_ER_avg_3 = rowMeans(select(., matches("^[NP]\\d+_ER_3$")), na.rm = TRUE),
    NP_ER_avg_4 = rowMeans(select(., matches("^[NP]\\d+_ER_4$")), na.rm = TRUE),
    NP_ER_avg_5 = rowMeans(select(., matches("^[NP]\\d+_ER_5$")), na.rm = TRUE),
    NP_ER_avg_6 = rowMeans(select(., matches("^[NP]\\d+_ER_6$")), na.rm = TRUE),
    NP_ER_avg_7 = rowMeans(select(., matches("^[NP]\\d+_ER_7$")), na.rm = TRUE)
  )

EMA_df %>%  select(matches("^P\\d+_ER_1$"))
EMA_df %>%  select(matches("^N\\d+_ER_1$"))
EMA_df %>%  select(matches("^[NP]\\d+_ER_1$"))
```

```{r Save data, eval=FALSE}
write.csv(EMA_df, paste0("Created_data/EMA_cleaned_SG_", Sys.Date(), ".csv"))
```

```{r Data dictionary}
filtered_df <- EMA_df[EMA_df$Day == 1, ]
dictionary <- create_dictionary(filtered_df)
write.csv(dictionary, paste0("Created_data/Data_dictionary_SG_", Sys.Date(), ".csv"))
```

```{r Descriptives}
# If the data isn't loaded from above, uncomment and run:
EMA_df <- read.csv("Created_data/EMA_cleaned_SG_2024-10-10.csv")

# Filter to day = 1
filtered_df <- EMA_df[EMA_df$Day == 1, ]

# subset the data
Subset_df <- filtered_df %>%
  select(all_of(c(
    
    # Pos/neg pre-averages 
    "N_pos_avg", "P_pos_avg", "NP_pos_avg",
    "N_neg_avg", "P_neg_avg", "NP_neg_avg",
    
    # Pos/neg post-averages
    "N_ERpos_avg", "P_ERpos_avg", "NP_ERpos_avg",
    "N_ERneg_avg", "P_ERneg_avg", "NP_ERneg_avg",
    
    # ER averages
    # "N_ER_avg_2", "P_ER_avg_2", "NP_ER_avg_2",
    "N_ER_avg_1", "P_ER_avg_1", "NP_ER_avg_1",
    
    # Change Scores
    "N_pos_change", "N_neg_change",
    "P_pos_change", "P_neg_change",
    "NP_pos_change", "NP_neg_change",
    
    # ER averages across items
    "N_ER_avg_1", "P_ER_avg_1", "NP_ER_avg_1",
    
    # indices relating to affect, symptoms, flexibility and ER measures
    "SSI", 
    "BDI",
    "EDS",
    "STAIS", "STAIT",
    "PCL",
    "GPTS_self", "GPTS_pers", "GPTS",  
    "SF36_RoleEmoProblem", "SF36_SociFunc",
    "DERS_Nonacceptance", "DERS_DiffGoalDirectedBehaviour", "DERS_Impulse", 
    "DERS_LackAwareness", "DERS_LackClarity", "DERS_LackStrategies",
    "CFS_Abandonment", "CFS_ReCoping", "CFS_MetaCoping", "CFS_Overall",
    "CDRISC", 
    
    # flexibility
    "P_IFI", "N_IFI"
  )))

(summary_output_1 <- dfSummary(Subset_df))
(summary_output_2 <- descr(Subset_df))
write.csv(summary_output_2, paste0("Created_data/Summary_output_SG_", 
                                   format(Sys.Date(), "%Y-%m-%d"), ".csv"), row.names = TRUE)
# Descriptives vis
## Histograms
plot_list <- list()
for (var in names(Subset_df)) {
  p <- ggplot(Subset_df, aes_string(x = var)) +
    geom_histogram(binwidth = 1, fill = 'blue', color = 'black', alpha = 0.7) +
    theme_minimal() +
    ggtitle(paste(var))
  plot_list[[var]] <- p
}

## Density
plot_list_2 <- list()
for (var in names(Subset_df)) {
  p <- ggplot(Subset_df, aes_string(x = var)) +
    geom_density(fill = 'blue', color = 'black', alpha = 0.7) +
    theme_minimal() +
    ggtitle(paste(var))
  plot_list_2[[var]] <- p
}

# Save histograms
png(paste0("Created_data/Var_hist_SG_", format(Sys.Date(), "%Y-%m-%d"), ".png"), width = 1100, height = 800)
grid.arrange(grobs = plot_list, ncol = 6)  
dev.off()

# Save densities
png(paste0("Created_data/Var_dens_SG_", format(Sys.Date(), "%Y-%m-%d"), ".png"), width = 1100, height = 800)
grid.arrange(grobs = plot_list_2, ncol = 6)  
dev.off()

# Correlations table
(Corr_table <- apa.cor.table(Subset_df, filename = paste0("Created_data/Correlations_SG_", 
                                                          format(Sys.Date(), "%Y-%m-%d"), ".doc"),
                             table.number = 1, 
                             show.conf.interval = TRUE, 
                             show.sig.stars = TRUE, 
                             landscape = TRUE))
```

# 2024-09-13 
```{r mt summary}
# ER strategy use as canonical loadings; set 1 = list of ER strategies & set 2 - symptoms; or two IFIs (P and N); or negative and positive affect changes (so the question becomes "among ER strategies, what are the ones that relate the most to flexibility, or some of the symptoms?")

# Categorize (e.g., just look at flexibility); 2) look at canonical correlations; 3) simplify! forget about P and N. Just focus on average for each trial (the NP variables I made for everyone); 4) later,if we start to see effects, is it driven by positive/negative? /// if we don't see effects, maybe it only applies to positive/negative?
```

```{r NP corrs}
EMA_df <- read.csv("Created_data/EMA_cleaned_SG_2024-10-10.csv")
filtered_df <- EMA_df[EMA_df$Day == 1, ]

# subset the data
Subset_df <- filtered_df %>%
  select(all_of(c(
    
    # Pos/neg pre-averages 
    "NP_pos_avg", "NP_neg_avg",
    
    # Pos/neg post-averages
    "NP_ERpos_avg", "NP_ERneg_avg",
    
    # ER averages
    "NP_ER_avg_2",

    # Change Scores
    "NP_pos_change", "NP_neg_change",
    
    # ER averages across items
    "NP_ER_avg_1",
        
    # flexibility
    "P_IFI", "N_IFI",
    
    # indices relating to affect, symptoms, flexibility and ER measures
    "SSI", 
    "BDI",
    "EDS",
    "STAIS", "STAIT",
    "PCL",
    "GPTS_self", "GPTS_pers", "GPTS",  
    "SF36_RoleEmoProblem", "SF36_SociFunc",
    "DERS_Nonacceptance", "DERS_DiffGoalDirectedBehaviour", "DERS_Impulse", 
    "DERS_LackAwareness", "DERS_LackClarity", "DERS_LackStrategies",
    "CFS_Abandonment", "CFS_ReCoping", "CFS_MetaCoping", "CFS_Overall",
    "CDRISC"
  )))

(Corr_table <- apa.cor.table(Subset_df, filename = paste0("Created_data/Correlations_SG_", 
                                                          format(Sys.Date(), "%Y-%m-%d"), ".doc"),
                             table.number = 1, 
                             show.conf.interval = TRUE, 
                             show.sig.stars = TRUE, 
                             landscape = TRUE))
str(Corr_table)
# Corr_table$table.body
Corr_table_df <- as.data.frame(Corr_table$table.body)
write.csv(Corr_table_df, paste0("Created_data/Correlations_SG_", Sys.Date(), ".csv")) 
```

```{r canonical correlations}
#### ER strategies across strategies ####

Set_1_NP_ER <- na.omit(EMA_df[, c("NP_ER_avg_1", "NP_ER_avg_2", "NP_ER_avg_3", "NP_ER_avg_4",
                                      "NP_ER_avg_5", "NP_ER_avg_6", "NP_ER_avg_7")])

Set_2_outcomes <- na.omit(EMA_df[, c("P_IFI", "N_IFI")])

# descriptives
ggpairs(Set_1_NP_ER)
ggpairs(Set_2_outcomes)

# standard correlations
corr <- matcor(Set_1_NP_ER, Set_2_outcomes)
img.matcor(corr, type = 2)

# Canonical correlations
canon <- cc(Set_1_NP_ER, Set_2_outcomes)
# canon    # all results
canon$cor
canon[3:4] # raw canonical coefficients. These are interpreted similarly to regression coefficients
plt.cc(canon, var.label = TRUE, ind.names = EMA_df[,1])  # Visualize

# tests of canonical dimensions (need 3 for this to make sense?)
rho <- canon$cor
n <- dim(Set_1_NP_ER)[1]
p <- length(Set_1_NP_ER)
q <- length(Set_2_outcomes)
p.asym(rho, n, p, q, tstat = "Wilks") # F-approximations for p val
p.asym(rho, n, p, q, tstat = "Hotelling")
p.asym(rho, n, p, q, tstat = "Pillai")

# loadings
canon_loads <- comput(Set_1_NP_ER, Set_2_outcomes, canon)
canon_loads[3:6] # canonical loadings. These are the correlations between the variables and canonical variates

# standardized canonical coefficients diagonal matrix of ER; interpret as standardized regression coefficients
s1 <- diag(sqrt(diag(cov(Set_1_NP_ER))))
s1 %*% canon$xcoef

# standardized canonical coefficients diagonal matrix of IFI
s2 <- diag(sqrt(diag(cov(Set_2_outcomes))))
s2 %*% canon$ycoef

#### ER in negative ####

# sets for canonical - ER strategy use in NEGATIVE scenarios
Set_1_N_ER <- na.omit(EMA_df[, c("N_ER_avg_1", "N_ER_avg_2", "N_ER_avg_3", "N_ER_avg_4",
                                     "N_ER_avg_5", "N_ER_avg_6", "N_ER_avg_7")])

# descriptives
ggpairs(Set_1_N_ER)
ggpairs(Set_2_outcomes)

# standard correlations
corr <- matcor(Set_1_N_ER, Set_2_outcomes)
img.matcor(corr, type = 2)

# Canonical correlations
canon <- cc(Set_1_N_ER, Set_2_outcomes)
# canon    # all results
canon$cor
canon[3:4] # raw canonical coefficients. These are interpreted similarly to regression coefficients
plt.cc(canon, var.label = TRUE, ind.names = EMA_df[,1])  # Visualize

# tests of canonical dimensions (need 3 for this to make sense?)
rho <- canon$cor
n <- dim(Set_1_N_ER)[1]
p <- length(Set_1_N_ER)
q <- length(Set_2_outcomes)
p.asym(rho, n, p, q, tstat = "Wilks") # F-approximations for p val
p.asym(rho, n, p, q, tstat = "Hotelling")
p.asym(rho, n, p, q, tstat = "Pillai")

# loadings
canon_loads <- comput(Set_1_N_ER, Set_2_outcomes, canon)
canon_loads[3:6] # canonical loadings. These are the correlations between the variables and canonical variates

# standardized canonical coefficients diagonal matrix of ER; interpret as standardized regression coefficients
s1 <- diag(sqrt(diag(cov(Set_1_N_ER))))
s1 %*% canon$xcoef

# standardized canonical coefficients diagonal matrix of IFI
s2 <- diag(sqrt(diag(cov(Set_2_outcomes))))
s2 %*% canon$ycoef

#### ER in positive ####

# sets for canonical - ER strategy use in positive scenarios
Set_1_P_ER <- na.omit(EMA_df[, c("P_ER_avg_1", "P_ER_avg_2", "P_ER_avg_3", "P_ER_avg_4",
                                     "P_ER_avg_5", "P_ER_avg_6", "P_ER_avg_7")])
# descriptives
ggpairs(Set_1_P_ER)
ggpairs(Set_2_outcomes)

# standard correlations
corr <- matcor(Set_1_P_ER, Set_2_outcomes)
img.matcor(corr, type = 2)

# Canonical correlations
canon <- cc(Set_1_P_ER, Set_2_outcomes)
# canon    # all results
canon$cor
canon[3:4] # raw canonical coefficients. These are interpreted similarly to regression coefficients
plt.cc(canon, var.label = TRUE, ind.names = EMA_df[,1])  # Visualize

# tests of canonical dimensions (need 3 for this to make sense?)
rho <- canon$cor
n <- dim(Set_1_P_ER)[1]
p <- length(Set_1_P_ER)
q <- length(Set_2_outcomes)
p.asym(rho, n, p, q, tstat = "Wilks") # F-approximations for p val
p.asym(rho, n, p, q, tstat = "Hotelling")
p.asym(rho, n, p, q, tstat = "Pillai")

# loadings
canon_loads <- comput(Set_1_P_ER, Set_2_outcomes, canon)
canon_loads[3:6] # canonical loadings. These are the correlations between the variables and canonical variates

# standardized canonical coefficients diagonal matrix of ER; interpret as standardized regression coefficients
s1 <- diag(sqrt(diag(cov(Set_1_P_ER))))
s1 %*% canon$xcoef

# standardized canonical coefficients diagonal matrix of IFI
s2 <- diag(sqrt(diag(cov(Set_2_outcomes))))
s2 %*% canon$ycoef
```

# verify CZs work
```{r CZ data}
EMA_df_CZ <- read_xlsx("Created_data/Data_Output_CZ_2024_09_19.xlsx")
```

